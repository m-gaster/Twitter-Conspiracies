{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_colwidth', 199)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_TWEETS_READ_PATH = r\"/arc/project/st-tlemieux-1/data/Cleaned-Labeled-Tweets/\"\n",
    "\n",
    "MERGED_TWEET_CHUNK_SAVE_PATH = r\"/scratch/st-tlemieux-1/lfrymire/BERT-input/FINAL-INPUTS/ALL-TWEETS/\" #this should be a folder containing three folders - one for each type of CT tweet (make sure it ends in a slash)\n",
    "\n",
    "# make subfolders:\n",
    "for type_of_tweets in [\"GEN-CT-Tweets\", \"COV-CT-Tweets\", \"NON-COV-CT-Tweets\"]:\n",
    "    \n",
    "    if not os.path.exists(MERGED_TWEET_CHUNK_SAVE_PATH + type_of_tweets + '/'):\n",
    "        os.makedirs(MERGED_TWEET_CHUNK_SAVE_PATH + type_of_tweets + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_folder(folder):\n",
    "    \n",
    "    return [f for f in listdir(folder) if isfile(join(folder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#users = get_files_in_folder(CLEAN_TWEETS_READ_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get subset of geolocated users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocated_users = pd.read_csv(r\"/arc/project/st-tlemieux-1/data/FINAL-CLEANED-GEOLOCATED-USERS.csv\")\n",
    "\n",
    "users = np.intersect1d(np.array(users), geolocated_users['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_CT_words_and_tags = [\n",
    "    'essentialworkers',\n",
    "    'pfizerproud',\n",
    "    'vaccineswork',\n",
    "    'sciencewillwin',\n",
    "    'flattenthecurve',\n",
    "    'maskssavelives'\n",
    "]\n",
    "\n",
    "non_CT_words_and_tags = non_CT_words_and_tags + [f'#{x}' for x in non_CT_words_and_tags]\n",
    "\n",
    "\n",
    "general_conspiracy_hashtags = [\n",
    "    'plandemic',\n",
    "    'scamdemic',\n",
    "    'covidhoax',\n",
    "    'nwo',\n",
    "    'covid1984',\n",
    "    'plandemia',\n",
    "    'agenda21',\n",
    "    'thegreatreset',\n",
    "    'agenda2030',\n",
    "    'newworldorder',\n",
    "    'wakeupamerica',\n",
    "#     'wakeup',\n",
    "    'openamericanow',\n",
    "    'firefauci',\n",
    "    'wwg1wga',\n",
    "    'qanon',\n",
    "    'coronahoax',\n",
    "    \n",
    "    'essentialworkers',\n",
    "    'pfizerproud',\n",
    "    'vaccineswork',\n",
    "    'sciencewillwin'\n",
    "]\n",
    "\n",
    "keywords = [\n",
    "    'plandemic',\n",
    "    'scamdemic',\n",
    "    'covidhoax',\n",
    "    'covid hoax',\n",
    "    'covid1984',\n",
    "    'plandemia',\n",
    "    'new world order',\n",
    "    'wake up america',\n",
    "    'open america now',\n",
    "    'fire fauci',\n",
    "    'wwg1wga',\n",
    "    'qanon',\n",
    "    'coronahoax',\n",
    "    'corona hoax',\n",
    "]\n",
    "\n",
    "CT_link_list = ['zerohedge.com', 'infowars.com', 'principia-scientific.com',\n",
    "'tx.voice-truth.com', 'humansarefree.com', 'activistpost.com',\n",
    "'gnews.org', 'wakingtimes.com', 'brighteon.com','thewallwillfall.org','sott.net',]\n",
    "\n",
    "\n",
    "hashtag_set = set(['#' + tag.upper() for tag in general_conspiracy_hashtags])\n",
    "keyword_set = set([x.upper() for x in keywords])\n",
    "\n",
    "# re_escape_keywords = '|'.join([re.escape(word) for word in keywords])\n",
    "# re_escape_links = '|'.join([re.escape(link) for link in CT_link_list])\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    input = tweet (str)\n",
    "    output = cleaned_tweet(str)\n",
    "    '''\n",
    "    return ' '.join([x.replace('#','') for x in tweet.split() if not (x.startswith(('http','@')) or x.upper() in keyword_set or x.upper() in hashtag_set or x.upper() in non_CT_words_and_tags)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = ['COVID-SPECIFIC CT Tweet (Dummy)', 'CT Tweet (Dummy)',\n",
    "       'NON-COVID CT Tweet (Dummy)', 'date', 'Cleaned Tweet',\n",
    "       'language', 'retweet']\n",
    "\n",
    "bool_cols = ['COVID-SPECIFIC CT Tweet (Dummy)', 'CT Tweet (Dummy)','NON-COVID CT Tweet (Dummy)', 'retweet']\n",
    "str_cols = ['date', 'Cleaned Tweet']\n",
    "\n",
    "float_cols = ['language']\n",
    "\n",
    "bool_cols_dict = {col:np.bool_ for col in bool_cols}\n",
    "str_cols_dict = {col:str for col in str_cols}\n",
    "float_cols_dict = {col:np.float16 for col in float_cols}\n",
    "\n",
    "datatypes = {**bool_cols_dict, **str_cols_dict, **float_cols_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_to_label_dict = {\"GEN-CT-Tweets\":'CT Tweet (Dummy)',\n",
    "                      \"COV-CT-Tweets\":'COVID-SPECIFIC CT Tweet (Dummy)',\n",
    "                      \"NON-COV-CT-Tweets\": 'NON-COVID CT Tweet (Dummy)'}\n",
    "               \n",
    "def read_and_process_df(USER_ID, READ_PATH, type_of_tweet, bad_list):\n",
    "    try:\n",
    "    \n",
    "        df = pd.read_csv(READ_PATH, usecols=cols_to_use, dtype=datatypes)\n",
    "\n",
    "        df['user_id'] = USER_ID\n",
    "        \n",
    "        df = df[df['language']==1]\n",
    "        \n",
    "        del df['language']\n",
    "        \n",
    "        df['Cleaned Tweets'] = df['Cleaned Tweets'].apply(clean_tweet)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        bad_list.append(USER_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NUM_CHUNKS = 40\n",
    "# user_chunk_splits = np.array_split(users, NUM_CHUNKS)\n",
    "\n",
    "USERS_PER_CHUNK = 4000\n",
    "user_chunk_splits = np.array_split(users, USERS_PER_CHUNK)\n",
    "\n",
    "unreadable_users = []\n",
    "\n",
    "for type_of_tweets in [\"COV-CT-Tweets\"]: #[\"GEN-CT-Tweets\", \"COV-CT-Tweets\", \"NON-COV-CT-Tweets\"]:\n",
    "\n",
    "    for i, chunk in tqdm(enumerate(range(0, len(user_chunk_splits)))):\n",
    "        \n",
    "        if os.path.exists(fr\"{MERGED_TWEET_CHUNK_SAVE_PATH}{type_of_tweets}/MERGED_CHUNK_{i}\"):\n",
    "            continue\n",
    "\n",
    "        chunk_read_paths = [CLEAN_TWEETS_READ_PATH + user for user in user_chunk_splits[i]]\n",
    "\n",
    "        users_and_paths = zip(user_chunk_splits[i], chunk_read_paths)\n",
    "        \n",
    "#         list_of_user_tweet_dfs = [read_and_process_df(USER_ID=user_path_tup[0],\n",
    "#                                                     READ_PATH=user_path_tup[1],\n",
    "#                                                     type_of_tweet=type_of_tweets,\n",
    "#                                                     bad_list=unreadable_users) for user_path_tup in users_and_paths]\n",
    "#         pd.concat(list_of_user_tweet_dfs).rename(columns={'Cleaned Tweet':'sentence1', type_to_label_dict[type_of_tweet]:'label'}).to_csv(fr\"{MERGED_TWEET_CHUNK_SAVE_PATH}{type_of_tweets}/MERGED_CHUNK_{i}\", index=False)\n",
    "\n",
    "    \n",
    "        pd.concat([read_and_process_df(USER_ID=user_path_tup[0],\n",
    "                                                    READ_PATH=user_path_tup[1],\n",
    "                                                    type_of_tweet=type_of_tweets,\n",
    "                                                    bad_list=unreadable_users) for user_path_tup in users_and_paths]).rename(columns={'Cleaned Tweet':'sentence1', type_to_label_dict[type_of_tweets]:'label'}).to_csv(fr\"{MERGED_TWEET_CHUNK_SAVE_PATH}{type_of_tweets}/MERGED_CHUNK_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read_and_process_df(USER_ID=2440925667,\n",
    "                    READ_PATH=r'/arc/project/st-tlemieux-1/data/Cleaned-Labeled-Tweets/2440925667_CLEANED_TWEETS.csv', \n",
    "                    type_of_tweet='COV-CT-Tweets', \n",
    "                    bad_list=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COVID-SPECIFIC CT Tweet (Dummy)</th>\n",
       "      <th>CT Tweet (Dummy)</th>\n",
       "      <th>NON-COVID CT Tweet (Dummy)</th>\n",
       "      <th>date</th>\n",
       "      <th>Cleaned Tweet</th>\n",
       "      <th>retweet</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-02-23 10:19:29</td>\n",
       "      <td>Fauci is a better actor than most of Hollywood! In other news, FireFauci</td>\n",
       "      <td>False</td>\n",
       "      <td>2440925667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10493</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-27 08:29:07</td>\n",
       "      <td>BLM is made up of primarily rich white basement dwellers w daddy's money WakeUpAmerica</td>\n",
       "      <td>False</td>\n",
       "      <td>2440925667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       COVID-SPECIFIC CT Tweet (Dummy)  CT Tweet (Dummy)  \\\n",
       "2426                              True              True   \n",
       "10493                             True              True   \n",
       "\n",
       "       NON-COVID CT Tweet (Dummy)                 date  \\\n",
       "2426                        False  2021-02-23 10:19:29   \n",
       "10493                       False  2020-07-27 08:29:07   \n",
       "\n",
       "                                                                                Cleaned Tweet  \\\n",
       "2426                 Fauci is a better actor than most of Hollywood! In other news, FireFauci   \n",
       "10493  BLM is made up of primarily rich white basement dwellers w daddy's money WakeUpAmerica   \n",
       "\n",
       "       retweet     user_id  \n",
       "2426     False  2440925667  \n",
       "10493    False  2440925667  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['COVID-SPECIFIC CT Tweet (Dummy)']==1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
