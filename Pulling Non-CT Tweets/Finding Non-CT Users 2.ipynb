{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --user --upgrade git+https://github.com/twintproject/twint.git@origin/master#egg=twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import twint\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta, date\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from collections import Counter\n",
    "from ast import literal_eval\n",
    "\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_colwidth', 199)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(df):\n",
    "    local_df = df\n",
    "    \n",
    "    #drop redundant cols\n",
    "    local_df.drop(['created_at', 'timezone', 'cashtags', 'user_id_str', 'photos', 'video', 'thumbnail', 'translate', 'trans_src', 'trans_dest', 'name', 'search'], axis=1, inplace=True)\n",
    "    \n",
    "    #convert date to datetime\n",
    "    local_df['date'] = pd.to_datetime(local_df['date'])\n",
    "    \n",
    "    return local_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tweets_in_date_range(search_terms, start_date, end_date, LOCAL_SAVE_PATH_ROOT):\n",
    "    '''    \n",
    "    search_terms = list of strings (or singleton) of search terms that will be in the tweet\n",
    "    \n",
    "    returns a pandas dataframe of tweets\n",
    "    '''\n",
    "    \n",
    "    search_string = \" OR \".join(search_terms)\n",
    "    \n",
    "    c = twint.Config()\n",
    "    \n",
    "#     date range of search\n",
    "    c.Since = start_date\n",
    "    c.Until = end_date\n",
    "    \n",
    "    c.Search = search_string\n",
    "    \n",
    "    # only collect a certain number of tweets\n",
    "#     c.Limit = num_tweets\n",
    "\n",
    "    # Don't print output\n",
    "    c.Hide_output = True\n",
    "    \n",
    "    # find shadow-banned accounts too - this apparently slows things down considerably\n",
    "    c.Profile_full = True\n",
    "\n",
    "#     c.Output = f\"{num_tweets} tweets - {start_date} to {end_date}.csv\"\n",
    "    c.Pandas = True\n",
    "\n",
    "    twint.run.Search(c)\n",
    "\n",
    "    return clean_tweets(twint.storage.panda.Tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#believescience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_CT_words_and_tags = [\n",
    "    'essentialworkers',\n",
    "    'pfizerproud',\n",
    "    'vaccineswork',\n",
    "    'sciencewillwin'\n",
    "]\n",
    "\n",
    "non_CT_words_and_tags = non_CT_words_and_tags + [f'#{x}' for x in non_CT_words_and_tags]\n",
    "\n",
    "test_search_terms = non_CT_words_and_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RefreshTokenException",
     "evalue": "Could not find the Guest token in HTML",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRefreshTokenException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1ef8aaeafbb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_tweets_in_date_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_terms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_search_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2020-01-01'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2021-07-07'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLOCAL_SAVE_PATH_ROOT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-1529a4053459>\u001b[0m in \u001b[0;36mfind_tweets_in_date_range\u001b[1;34m(search_terms, start_date, end_date, LOCAL_SAVE_PATH_ROOT)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPandas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mtwint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclean_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpanda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTweets_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\twint\\run.py\u001b[0m in \u001b[0;36mSearch\u001b[1;34m(config, callback)\u001b[0m\n\u001b[0;32m    408\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFollowers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPandas_au\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpanda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_autoget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tweet\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\twint\\run.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(config, callback)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m     \u001b[0mget_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTwint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\twint\\run.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# USAGE : to get a new guest token simply do `self.token.refresh()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToken\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatabase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatelock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUntil\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSince\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\twint\\token.py\u001b[0m in \u001b[0;36mrefresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGuest_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRefreshTokenException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Could not find the Guest token in HTML'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRefreshTokenException\u001b[0m: Could not find the Guest token in HTML"
     ]
    }
   ],
   "source": [
    "test = find_tweets_in_date_range(search_terms=test_search_terms, start_date='2020-01-01', end_date='2021-07-07', LOCAL_SAVE_PATH_ROOT=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(r\"#essentialworkers, #pfizerproud, #vaccineswork, #sciencewillwin.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Non-CT Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Users Who Are Also Flagged for CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_overlapped_users(df1, df2):\n",
    "    '''\n",
    "    Both DataFrames must have user ID (or something like that) as index\n",
    "    '''\n",
    "    \n",
    "    intersection_of_users = np.intersect1d(df1.index, df2.index)\n",
    "    \n",
    "    df1['In CT and Non-CT DFs'] = 0\n",
    "    df2['In CT and Non-CT DFs'] = 0\n",
    "    \n",
    "    df1['In CT and Non-CT DFs'].loc[intersection_of_users] = 1\n",
    "    df2['In CT and Non-CT DFs'].loc[intersection_of_users] = 1\n",
    "\n",
    "    return df1, df2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_USER_PATH = r\"C:/Users/crackcocaine69xxx/Python Stuff/594/Twint/Geo Cross Referencing/Master User List - GEOLOCATED.csv\"\n",
    "\n",
    "ALL_CT_USERS = pd.read_csv(MASTER_USER_PATH).set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_CT_tweets_2 = pd.read_csv(r\"#essentialworkers, #pfizerproud, #vaccineswork, #sciencewillwin.csv\")\n",
    "\n",
    "non_CT_tweets_2 = non_CT_tweets_2.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_CT_tweets_2, ALL_CT_USERS = label_overlapped_users(non_CT_tweets_2, ALL_CT_USERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_CT_tweets_2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Label Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword lists and such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_conspiracy_hashtags = [\n",
    "    'plandemic',\n",
    "    'scamdemic',\n",
    "    'covidhoax',\n",
    "    'nwo',\n",
    "    'covid1984',\n",
    "    'plandemia',\n",
    "    'agenda21',\n",
    "    'thegreatreset',\n",
    "    'agenda2030',\n",
    "    'newworldorder',\n",
    "    'wakeupamerica',\n",
    "#     'wakeup',\n",
    "    'openamericanow',\n",
    "    'firefauci',\n",
    "    'wwg1wga',\n",
    "    'qanon',\n",
    "    'coronahoax'\n",
    "]\n",
    "\n",
    "keywords = [\n",
    "    'plandemic',\n",
    "    'scamdemic',\n",
    "    'covidhoax',\n",
    "    'covid hoax',\n",
    "    'covid1984',\n",
    "    'plandemia',\n",
    "    'new world order',\n",
    "    'wake up america',\n",
    "    'open america now',\n",
    "    'fire fauci',\n",
    "    'wwg1wga',\n",
    "    'qanon',\n",
    "    'coronahoax',\n",
    "    'corona hoax',\n",
    "]\n",
    "\n",
    "CT_link_list = ['zerohedge.com', 'infowars.com', 'principia-scientific.com',\n",
    "'tx.voice-truth.com', 'humansarefree.com', 'activistpost.com'\n",
    "'gnews.org', 'wakingtimes.com', 'brighteon.com','thewallwillfall.org','sott.net',]\n",
    "\n",
    "\n",
    "hashtag_set = set(['#' + tag for tag in general_conspiracy_hashtags])\n",
    "keyword_set = set(keywords)\n",
    "\n",
    "re_escape_keywords = '|'.join([re.escape(word) for word in keywords])\n",
    "re_escape_links = '|'.join([re.escape(link) for link in CT_link_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions for Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_in_list(list_of_hashtags_in_tweet):\n",
    "    return any(hashtag.upper() in [tag.upper() for tag in list_of_hashtags_in_tweet] for hashtag in general_conspiracy_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    input = tweet (str)\n",
    "    output = cleaned_tweet(str)\n",
    "    '''\n",
    "    \n",
    "#     return [['CLS']] + [x.replace('#','') for x in tweet.split() if not (x.startswith(('http','@')) or x in keyword_set or x in hashtag_set)] + [['SEP']]\n",
    "    return ' '.join([x.replace('#','') for x in tweet.split() if not (x.startswith(('http','@')) or x in keyword_set or x in hashtag_set)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_CT_tweets(df):\n",
    "    \n",
    "    return ( df['tweet'].str.contains(re_escape_keywords, case=False) | df['urls'].str.contains(re_escape_links, case=False) | df['hashtags'].apply(hashtag_in_list)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_CT_tweets_2['CT Tweet'] = label_CT_tweets(non_CT_tweets_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_CT_tweets_2 = non_CT_tweets_2[non_CT_tweets_2['language']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_CT_tweets_2.to_csv(r\"Semi-Cleaned #essentialworkers, #pfizerproud, #vaccineswork, #sciencewillwin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_CT_tweets_2 = pd.read_csv(r\"Semi-Cleaned #essentialworkers, #pfizerproud, #vaccineswork, #sciencewillwin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_CT_tweets_2['Cleaned Tweet'] = non_CT_tweets_2['tweet'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_CT_tweets_2[(non_CT_tweets_2['Cleaned Tweet'].map(len) > 4)][['Cleaned Tweet', 'CT Tweet']].to_csv(r'#essentialworkers, #pfizerproud, #vaccineswork, #sciencewillwin - CLEANED FOR BERT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(non_CT_tweets_2['Cleaned Tweet'].str.split().map(len) > 4).sum() / len(non_CT_tweets_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
