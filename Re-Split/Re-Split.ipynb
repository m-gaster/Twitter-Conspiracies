{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import twint\n",
    "# import time\n",
    "# from datetime import datetime\n",
    "# from datetime import timedelta, date\n",
    "# from collections import Counter\n",
    "# from ast import literal_eval\n",
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_colwidth', 199)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXISTING_LOOKUPS_PATHS_ROOT = r\"C:/Users/crackcocaine69xxx/Python Stuff/594/Twint/Looking Up All Conspiracy Hashtag User Tweets/All Conspiracy Tweeters' Tweets/Split\"    # folder which contains folders which contain CT account tweets\n",
    "EXISTING_LOOKUPS_PATHS = [ EXISTING_LOOKUPS_PATHS_ROOT + f\" {split}/\" for split in [5,6,7,8,9] ]      # list of folders which contain CT account tweets\n",
    "\n",
    "NOTEBOOK_TEMPLATE_PATH = r\"C:/Users/crackcocaine69xxx/Python Stuff/594/Twint/Re-Split Lookup/Tweet Lookup TEMPLATE.ipynb\"    # path containing .json format of jupyter file template for the lookup\n",
    "\n",
    "NEW_LOOKUPS_PATH_ROOT = r\"C:/Users/crackcocaine69xxx/Python Stuff/594/Twint/Looking Up All Conspiracy Hashtag User Tweets/New Split Tweet Lookups/\"    # folder which contains folder for each split\n",
    "\n",
    "NEW_SPLIT_LIST_SAVE_PATH = r\"C:/Users/crackcocaine69xxx/Python Stuff/594/Twint/Getting Conspiracy Hashtag Users/New Splits/\"    # folder containing all N splits of the master user list\n",
    "\n",
    "NEW_NOTEBOOKS_PATH_ROOT = r\"C:/Users/crackcocaine69xxx/Python Stuff/594/Twint/Looking Up All Conspiracy Hashtag User Tweets/New Split Scripts/\"    # where to save the new .ipynb notebooks\n",
    "\n",
    "MASTER_USER_LIST_PATH = r\"C:/Users/crackcocaine69xxx/Python Stuff/594/Twint/MASTER LIST - All CT Link and Hashtag Users/All CT Link and Hashtag Users.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Num Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SPLITS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new folders to put splits in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_id_split_save_paths = []\n",
    "\n",
    "for split in range(0, NUM_SPLITS):\n",
    "    \n",
    "    newpath = fr'{NEW_LOOKUPS_PATH_ROOT}Split {split}' \n",
    "    \n",
    "    all_id_split_save_paths.append(newpath)\n",
    "    \n",
    "    # make a new folder\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Split User ID List\n",
    "\n",
    "1. Find users who have been looked up already\n",
    "    * Mine\n",
    "    * Luke's\n",
    "2. Bring that information into the master list of users\n",
    "3. Use ARC to find all users in our master list with GeoCov19 locations\n",
    "    * Do this so we can search them first\n",
    "4. Split the users into mine and luke's (only returning the users who haven't been searched up)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all users who have been searched\n",
    "\n",
    "Luke needs to run the following 5 cells and send me the output (the users he's already searched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_searched_ids(path):\n",
    "    \n",
    "    return [int(f.split('_')[0]) for f in listdir(path) if isfile(join(path, f))]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_searched_users(split_list):\n",
    "    '''\n",
    "    input = list of splits (ints) detailing which split of the dataset we're recovering (e.g. I'm doing [5,6,7,8,9])\n",
    "    output = np.array of all users (hashtag and link) who have been searched for\n",
    "    '''   \n",
    "    \n",
    "    #create a list of all users we've searched for\n",
    "    all_searched_users = []\n",
    "    \n",
    "    for split in split_list:\n",
    "\n",
    "        split_n_path = EXISTING_LOOKUPS_PATHS_ROOT + \" \" + str(split)\n",
    "\n",
    "        searched_users = recover_searched_ids(split_n_path)\n",
    "        \n",
    "        all_searched_users += searched_users\n",
    "        \n",
    "    return np.array(all_searched_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_search_updated_dataset(split_list):\n",
    "    '''\n",
    "    input = list of splits (ints) detailing which split of the dataset we're recovering (e.g. I'm doing [5,6,7,8,9])\n",
    "    output = dataframe of all users (hashtag and link) which is updated with searched account['Searched'] == 1\n",
    "    '''   \n",
    "    all_searched_users = find_searched_users(split_list)\n",
    "        \n",
    "    # bring list of searched users into master list\n",
    "    all_users = pd.read_csv(MASTER_USER_LIST_PATH).set_index('ID')\n",
    "    \n",
    "    if 'Searched' not in all_users.columns:\n",
    "        all_users['Searched'] = 0\n",
    "        \n",
    "    if 'Error' not in all_users.columns:\n",
    "        all_users['Error'] = 0\n",
    "    \n",
    "    all_users['Searched'].loc[all_searched_users] = 1\n",
    "\n",
    "    \n",
    "    return all_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASTER_USER_LIST = recreate_search_updated_dataset([5,6,7,8,9])\n",
    "\n",
    "# MASTER_USER_LIST[['Num CT Tweets - HT', 'Num CT Tweets - LINK']] = MASTER_USER_LIST[['Num CT Tweets - HT', 'Num CT Tweets - LINK']].fillna(0)\n",
    "\n",
    "# MASTER_USER_LIST.sort_values(by=['Num CT Tweets - HT', 'Num CT Tweets - LINK'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "mikhael_searched_users = find_searched_users([5,6,7,8,9])\n",
    "lukes_searched_users = pd.read_csv(r\"C:/Users/crackcocaine69xxx/Python Stuff/594/Twint/Re-Split Lookup/users luke has looked up.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_SEARCHED_USERS = np.concatenate([lukes_searched_users['0'].to_numpy(), mikhael_searched_users])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "ALL_CT_USERS = pd.read_csv(MASTER_USER_LIST_PATH)\n",
    "\n",
    "ALL_CT_USERS['Searched'] = 0\n",
    "\n",
    "ALL_CT_USERS['Error'] = 0\n",
    "\n",
    "ALL_CT_USERS.set_index('ID', inplace=True)\n",
    "\n",
    "ALL_CT_USERS.rename(columns={'Unnamed: 0': 'Original Order'})\n",
    "\n",
    "ALL_CT_USERS['Searched'].loc[ALL_SEARCHED_USERS] = 1\n",
    "\n",
    "ALL_CT_USERS[['Num CT Tweets - HT', 'Num CT Tweets - LINK']] = ALL_CT_USERS[['Num CT Tweets - HT', 'Num CT Tweets - LINK']].fillna(0)\n",
    "\n",
    "# ALL_CT_USERS.sort_values(by=['Num CT Tweets - HT', 'Num CT Tweets - LINK'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weighted score to sort CT users by\n",
    "ALL_CT_USERS['Weighted Num Tweets'] = ALL_CT_USERS['Num CT Tweets - HT']/ALL_CT_USERS['Num CT Tweets - HT'].sum()\n",
    "ALL_CT_USERS['Weighted Num Links'] = ALL_CT_USERS['Num CT Tweets - LINK']/ALL_CT_USERS['Num CT Tweets - LINK'].sum()\n",
    "ALL_CT_USERS['Weighted CT Score'] = ALL_CT_USERS['Weighted Num Links'] + ALL_CT_USERS['Weighted Num Tweets']\n",
    "\n",
    "ALL_CT_USERS.sort_values(['Weighted CT Score'], ascending=False, inplace=True)\n",
    "\n",
    "# ALL_CT_USERS.drop(['Weighted CT Score', 'Weighted Num Tweets', 'Weighted Num Links'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_to_search = ALL_CT_USERS[ ALL_CT_USERS['Searched']==0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "luke_users_to_search = users_to_search[0::2]\n",
    "mikhael_users_to_search = users_to_search[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "lukes_splits = {split:luke_users_to_search[split::NUM_SPLITS] for split in range(0, NUM_SPLITS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "mikhaels_splits = {split:mikhael_users_to_search[split::NUM_SPLITS] for split in range(0, NUM_SPLITS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in range(0, NUM_SPLITS):\n",
    "    mikhaels_splits[split].to_csv(NEW_SPLIT_LIST_SAVE_PATH + f\"Split {split}.csv\")\n",
    "\n",
    "LUKES_SPLIT_PATH = r\"C:/Users/crackcocaine69xxx/Python Stuff/594/Twint/Getting Conspiracy Hashtag Users/New Splits for Luke/\"\n",
    "for split in range(0, NUM_SPLITS):\n",
    "    lukes_splits[split].to_csv(LUKES_SPLIT_PATH + f\"Split {split}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out new split of users (links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_user_df = pd.read_csv(r\"C:/Users/crackcocaine69xxx/Python Stuff/594/Twint/Getting Conspiracy Link Users/All Link Users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_user_ids = link_user_df['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_user_ids = np.array_split(link_user_ids, 2)\n",
    "\n",
    "lukes_link_users = link_user_ids[0]\n",
    "mikhaels_link_users = link_user_ids[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting old and new splits together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "luke_final_users = list(lukes_link_users) + list(lukes_og_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "mikhaels_final_users = list(mikhaels_link_users) + list(mikhaels_og_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_split_n_notebook(split):\n",
    "    \n",
    "    save_ipynb_path = NEW_NOTEBOOKS_PATH_ROOT + f'Split {split}.ipynb'\n",
    "    \n",
    "    save_path_for_this_splits_users = NEW_LOOKUPS_PATH_ROOT + f'Split {split}'\n",
    "    \n",
    "    save_path_to_update_searched_users = NEW_SPLIT_LIST_SAVE_PATH + f'Split {split}.csv'\n",
    "    \n",
    "    with open(NOTEBOOK_TEMPLATE_PATH, 'r') as fp:\n",
    "        notebook = json.load(fp)\n",
    "    \n",
    "    for cell in notebook['cells']:\n",
    "        if cell['cell_type']=='code':\n",
    "            cell['source'] = [x.replace('REPLACE_SPLIT_USER_IDS_PATH', \"'\" + save_path_to_update_searched_users + \"'\").replace('REPLACE_PATH_ROOT', \"'\" + save_path_for_this_splits_users + \"/'\").replace('REPLACE_WITH_SPLIT_NUMBER', str(split)) for x in cell['source']]\n",
    "            \n",
    "    with open(save_ipynb_path, 'w') as fp:\n",
    "        json.dump(notebook, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in range(0, NUM_SPLITS):\n",
    "    gen_split_n_notebook(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run New Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'r\"C:\\\\Users\\\\crackcocaine69xxx\\\\Python.py'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_lst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_finder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\IPython\\utils\\path.py\u001b[0m in \u001b[0;36mget_py_filename\u001b[1;34m(name, force_win32)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'File `%r` not found.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: File `'r\"C:\\\\Users\\\\crackcocaine69xxx\\\\Python.py'` not found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-229-bfe9355dd448>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r\"C:\\\\Users\\\\crackcocaine69xxx\\\\Python Stuff\\\\594\\\\Twint\\\\Looking Up All Conspiracy Hashtag User Tweets\\\\New Split Scripts\\\\Split 0.ipynb\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2325\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2326\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2327\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2328\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    712\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nt'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"^'.*'$\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'For Windows, use double quotes to wrap a filename: %run \"mypath\\\\myfile.py\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: File `'r\"C:\\\\Users\\\\crackcocaine69xxx\\\\Python.py'` not found."
     ]
    }
   ],
   "source": [
    "%run r\"C:\\Users\\crackcocaine69xxx\\Python Stuff\\594\\Twint\\Looking Up All Conspiracy Hashtag User Tweets\\New Split Scripts\\Split 0.ipynb\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
