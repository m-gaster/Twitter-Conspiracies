{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:97.5% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:97.5% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective of this file:\n",
    "\n",
    "1. Count total *CT* tweets per day per user\n",
    "    * Hashtags\n",
    "    * Links\n",
    "2. Count total tweets per day per user\n",
    "3. Use (1) and (2) to get CT tweets per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File containing list of users and their locations\n",
    "USER_LOC_PATH = r\"C:/Users/mikha/OneDrive/Desktop/Dropbox/MIKHAEL NEW/mikhael school/Grad School/Master's/594/Data/Twint Data/2270718426_TWEETS.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashtag and Link Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "general_conspiracy_hashtags = [\n",
    "    'plandemic',\n",
    "    'scamdemic',\n",
    "    'covidhoax',\n",
    "    'nwo',\n",
    "    'covid1984',\n",
    "    'plandemia',\n",
    "    'agenda21',\n",
    "    'thegreatreset',\n",
    "    'agenda2030',\n",
    "    'newworldorder',\n",
    "    'wakeupamerica',\n",
    "    'wakeup',\n",
    "    'openamericanow',\n",
    "    'firefauci',\n",
    "    'wwg1wga',\n",
    "    'qanon',\n",
    "    'coronahoax'\n",
    "]\n",
    "\n",
    "# CHANGE THESE LATER\n",
    "CT_link_list = ['zerohedge.com', 'infowars.com', 'principia-scientific.com',\n",
    "'tx.voice-truth.com', 'humansarefree.com', 'activistpost.com'\n",
    "'gnews.org', 'wakingtimes.com', 'brighteon.com','thewallwillfall.org','sott.net',]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns to aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_tag_cols = ['date',\n",
    " 'Link - zerohedge.com - POST',\n",
    " 'Link - zerohedge.com - RETWEET',\n",
    " 'Link - zerohedge.com - TOTAL',\n",
    " 'Link - infowars.com - POST',\n",
    " 'Link - infowars.com - RETWEET',\n",
    " 'Link - infowars.com - TOTAL',\n",
    " 'Link - principia-scientific.com - POST',\n",
    " 'Link - principia-scientific.com - RETWEET',\n",
    " 'Link - principia-scientific.com - TOTAL',\n",
    " 'Link - tx.voice-truth.com - POST',\n",
    " 'Link - tx.voice-truth.com - RETWEET',\n",
    " 'Link - tx.voice-truth.com - TOTAL',\n",
    " 'Link - humansarefree.com - POST',\n",
    " 'Link - humansarefree.com - RETWEET',\n",
    " 'Link - humansarefree.com - TOTAL',\n",
    " 'Link - activistpost.comgnews.org - POST',\n",
    " 'Link - activistpost.comgnews.org - RETWEET',\n",
    " 'Link - activistpost.comgnews.org - TOTAL',\n",
    " 'Link - wakingtimes.com - POST',\n",
    " 'Link - wakingtimes.com - RETWEET',\n",
    " 'Link - wakingtimes.com - TOTAL',\n",
    " 'Link - brighteon.com - POST',\n",
    " 'Link - brighteon.com - RETWEET',\n",
    " 'Link - brighteon.com - TOTAL',\n",
    " 'Tag - plandemic - POST',\n",
    " 'Tag - plandemic - RETWEET',\n",
    " 'Tag - plandemic - TOTAL',\n",
    " 'Tag - scamdemic - POST',\n",
    " 'Tag - scamdemic - RETWEET',\n",
    " 'Tag - scamdemic - TOTAL',\n",
    " 'Tag - covidhoax - POST',\n",
    " 'Tag - covidhoax - RETWEET',\n",
    " 'Tag - covidhoax - TOTAL',\n",
    " 'Tag - nwo - POST',\n",
    " 'Tag - nwo - RETWEET',\n",
    " 'Tag - nwo - TOTAL',\n",
    " 'Tag - covid1984 - POST',\n",
    " 'Tag - covid1984 - RETWEET',\n",
    " 'Tag - covid1984 - TOTAL',\n",
    " 'Tag - plandemia - POST',\n",
    " 'Tag - plandemia - RETWEET',\n",
    " 'Tag - plandemia - TOTAL',\n",
    " 'Tag - agenda21 - POST',\n",
    " 'Tag - agenda21 - RETWEET',\n",
    " 'Tag - agenda21 - TOTAL',\n",
    " 'Tag - thegreatreset - POST',\n",
    " 'Tag - thegreatreset - RETWEET',\n",
    " 'Tag - thegreatreset - TOTAL',\n",
    " 'Tag - agenda2030 - POST',\n",
    " 'Tag - agenda2030 - RETWEET',\n",
    " 'Tag - agenda2030 - TOTAL',\n",
    " 'Tag - newworldorder - POST',\n",
    " 'Tag - newworldorder - RETWEET',\n",
    " 'Tag - newworldorder - TOTAL',\n",
    " 'Tag - wakeupamerica - POST',\n",
    " 'Tag - wakeupamerica - RETWEET',\n",
    " 'Tag - wakeupamerica - TOTAL',\n",
    " 'Tag - wakeup - POST',\n",
    " 'Tag - wakeup - RETWEET',\n",
    " 'Tag - wakeup - TOTAL',\n",
    " 'Tag - openamericanow - POST',\n",
    " 'Tag - openamericanow - RETWEET',\n",
    " 'Tag - openamericanow - TOTAL',\n",
    " 'Tag - firefauci - POST',\n",
    " 'Tag - firefauci - RETWEET',\n",
    " 'Tag - firefauci - TOTAL',\n",
    " 'Tag - wwg1wga - POST',\n",
    " 'Tag - wwg1wga - RETWEET',\n",
    " 'Tag - wwg1wga - TOTAL',\n",
    " 'Tag - qanon - POST',\n",
    " 'Tag - qanon - RETWEET',\n",
    " 'Tag - qanon - TOTAL',\n",
    " 'Tag - coronahoax - POST',\n",
    " 'Tag - coronahoax - RETWEET',\n",
    " 'Tag - coronahoax - TOTAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column subsets (done here - outside of the fnc. - to save time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtagged_post_cols = [x for x in link_tag_cols if x.startswith('Tag') and x.endswith('POST')]\n",
    "hashtagged_retweet_cols = [x for x in link_tag_cols if x.startswith('Tag') and x.endswith('RETWEET')]\n",
    "\n",
    "link_post_cols = [x for x in link_tag_cols if x.startswith('Link') and x.endswith('POST')]\n",
    "link_retweet_cols = [x for x in link_tag_cols if x.startswith('Link') and x.endswith('RETWEET')]\n",
    "\n",
    "front_cols = [ 'TOTAL CT Activity', 'TOTAL Tags', 'TOTAL Post Tags', 'TOTAL Retweet Tags', 'TOTAL Links', 'TOTAL Post Links', 'TOTAL Retweet Links']\n",
    "back_cols = [col for col in link_tag_cols if col not in front_cols and col != 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     32
    ]
   },
   "outputs": [],
   "source": [
    "def agg_by_week(READ_PATH, SAVE_PATH):\n",
    "    \n",
    "    df = pd.read_csv(READ_PATH, parse_dates=['date'])#.set_index('retweet')\n",
    "        \n",
    "    # create dummies for each hashtag and link (in each tweet)    \n",
    "    for link in CT_link_list:\n",
    "        df[f'Link - {link} - POST'] = ((df['urls'].str.contains(link, case=False)) & (df['retweet']==False)).astype(int)\n",
    "        df[f'Link - {link} - RETWEET'] = ((df['urls'].str.contains(link, case=False)) & (df['retweet']==True)).astype(int)\n",
    "        df[f'Link - {link} - TOTAL'] = df[f'Link - {link} - POST'] + df[f'Link - {link} - RETWEET']\n",
    "    \n",
    "    for tag in general_conspiracy_hashtags:\n",
    "        df[f'Tag - {tag} - POST'] = ((df['hashtags'].str.contains(tag, case=False)) & (df['retweet']==False)).astype(int)\n",
    "        df[f'Tag - {tag} - RETWEET'] = ((df['hashtags'].str.contains(tag, case=False)) & (df['retweet']==True)).astype(int)\n",
    "        df[f'Tag - {tag} - TOTAL'] = df[f'Tag - {tag} - POST'] + df[f'Tag - {tag} - RETWEET']\n",
    "    \n",
    "    # aggregate by weekly time period\n",
    "    df = df[link_tag_cols].groupby(pd.Grouper(key='date', freq='1W')).sum()\n",
    "    \n",
    "    # create totalling columns\n",
    "    df['TOTAL Post Tags'] = df[hashtagged_post_cols].sum(axis=1)\n",
    "    df['TOTAL Retweet Tags'] = df[hashtagged_retweet_cols].sum(axis=1)\n",
    "    df['TOTAL Tags'] = df['TOTAL Post Tags'] + df['TOTAL Retweet Tags']\n",
    "    \n",
    "    df['TOTAL Post Links'] = df[link_post_cols].sum(axis=1)\n",
    "    df['TOTAL Retweet Links'] = df[link_retweet_cols].sum(axis=1)\n",
    "    df['TOTAL Links'] = df['TOTAL Post Links'] + df['TOTAL Retweet Links']\n",
    "    \n",
    "    df['TOTAL CT Activity'] = df['TOTAL Links'] + df['TOTAL Tags']\n",
    "    \n",
    "    # re-order columns to have more important ones at the beginning (not important but nice to do)\n",
    "    df = df[front_cols + back_cols]\n",
    "    \n",
    "    df.to_csv(SAVE_PATH, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Final Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder containing folders of all split user lookups\n",
    "OG_READ_PATH_ROOT = r\"C:\\Users\\crackcocaine69xxx\\Python Stuff\\594\\Twint\\Looking Up All Conspiracy Hashtag User Tweets\\All Conspiracy Tweeters' Tweets\"\n",
    "\n",
    "# folder which will contain folders of all split user lookup AGGREGATIONS (weekly CT activity)\n",
    "OG_WRITE_PATH_ROOT = r\"C:\\Users\\crackcocaine69xxx\\Python Stuff\\594\\Twint\\Looking Up All Conspiracy Hashtag User Tweets\\OG Processed Tweets (naive counting CT activity)\"\n",
    "\n",
    "og_splits = [5,6,7,8,9]\n",
    "\n",
    "for split in og_splits:\n",
    "    local_read_path_root = OG_READ_PATH_ROOT + f'Split {split}/'\n",
    "    local_write_path_root = OG_WRITE_PATH_ROOT + f'Split {split}/'\n",
    "    \n",
    "    # make new folders to store processed tweets\n",
    "    if not os.path.exists(local_write_path_root):\n",
    "        os.makedirs(local_write_path_root)\n",
    "    \n",
    "    # find all users who have been searched and stored in this folder\n",
    "    users_in_this_split = [int(f.split('_')[0]) for f in listdir(local_read_path_root) if isfile(join(local_read_path_root, f))]\n",
    "\n",
    "    # aggregate each user's tweets\n",
    "    for user in users_in_this_split:\n",
    "        agg_by_week(READ_PATH=local_read_path_root+f'{user}_TWEETS.csv', SAVE_PATH=local_write_path_root+f'{user}_AGGREGATED.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
