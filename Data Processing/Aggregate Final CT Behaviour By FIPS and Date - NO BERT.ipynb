{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN THIS AFTER CONCATENATING BERT OUTPUT TO CSV'S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_colwidth', 199)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGGREGATING USER BEHAVIOUR BY DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_TWEET_CHUNK_READ_PATH = r\"/scratch/st-tlemieux-1/lfrymire/BERT-input/FINAL-INPUTS/ALL-TWEETS/COV-CT-Tweets/\" #this should be a folder containing three folders - one for each type of CT tweet (make sure it ends in a slash)\n",
    "\n",
    "AGGREGATED_TWEET_CHUNK_SAVE_PATH = r\"/scratch/st-tlemieux-1/lfrymire/BERT-OUTPUT/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_folder(folder):\n",
    "    \n",
    "    return [f for f in listdir(folder) if isfile(join(folder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_paths = get_files_in_folder(MERGED_TWEET_CHUNK_READ_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_paths = [x for x in chunk_paths if not 'TEST' in x and len(x) < 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "cols_to_use = ['sentence1', 'user_id', 'label',\n",
    "               'CT Tweet (Dummy)','NON-COVID CT Tweet (Dummy)', 'date', 'retweet']\n",
    "\n",
    "bool_cols = ['label', 'CT Tweet (Dummy)','NON-COVID CT Tweet (Dummy)', 'retweet']\n",
    "int_cols = ['user_ID']\n",
    "# str_cols = ['Cleaned Tweet']\n",
    "\n",
    "# obj_cols = ['language']\n",
    "\n",
    "bool_cols_dict = {col:np.bool_ for col in bool_cols}\n",
    "int_cols_dict = {col:np.int0 for col in int_cols}\n",
    "# str_cols_dict = {col:str for col in str_cols}\n",
    "# obj_cols_dict = {col:str for col in obj_cols}\n",
    "\n",
    "# datatypes = {**bool_cols_dict, **str_cols_dict, **obj_cols_dict}\n",
    "# datatypes = {**bool_cols_dict, **obj_cols_dict}\n",
    "datatypes = {**bool_cols_dict, **int_cols_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(s):\n",
    "    return datetime.date(int(s[0:4]), int(s[5:7]), int(s[8:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {'COVID-SPECIFIC CT Tweet (Dummy)':['mean', 'sum'],\n",
    "            'CT Tweet (Dummy)':['mean','sum'],\n",
    "            'NON-COVID CT Tweet (Dummy)':['mean','sum'],\n",
    "            'retweet':['mean', 'size'],\n",
    "            'Non-CT Tweet':['mean','sum']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_dates(user):\n",
    "    missing_dates = np.setdiff1d(all_dates, collapsed_chunk.loc[user, 'date'].unique())    \n",
    "    return missing_dates\n",
    "\n",
    "def fill_missing_dates(collapsed_chunk):\n",
    "    \n",
    "    users_to_delete = []\n",
    "    \n",
    "    missing_dates_df_dict = {col:[] for col in collapsed_chunk.reset_index().columns}\n",
    "    non_date_user_cols = [key for key in missing_dates_df_dict.keys() if not key in ('date', 'user_id')]\n",
    "\n",
    "    for user in collapsed_chunk.index.unique():\n",
    "        \n",
    "        # find all missing dates\n",
    "        try:\n",
    "            missing_dates = get_missing_dates(user)\n",
    "            \n",
    "            # append np.arrays of missing values (dates, user_id, and then zeros) to dictionary\n",
    "            missing_dates_df_dict['date'].append(missing_dates)\n",
    "            missing_dates_df_dict['user_id'].append(np.array([user]*len(missing_dates)))\n",
    "            for col in non_date_user_cols:\n",
    "                missing_dates_df_dict[col].append(np.zeros(len(missing_dates)))\n",
    "        except:\n",
    "            users_to_delete.append(user)\n",
    "            continue\n",
    "\n",
    "    # flatten list of np arrays\n",
    "    for col in missing_dates_df_dict:\n",
    "        missing_dates_df_dict[col] = np.concatenate(missing_dates_df_dict[col]).ravel()\n",
    "\n",
    "    # convert to dataframe    \n",
    "    missing_dates_df = pd.DataFrame(missing_dates_df_dict)\n",
    "    \n",
    "    collapsed_chunk.drop(users_to_delete, inplace=True)\n",
    "    \n",
    "    collapsed_chunk.reset_index(inplace=True)\n",
    "    \n",
    "    return collapsed_chunk.append(missing_dates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {('COVID-SPECIFIC CT Tweet (Dummy)', 'mean'):'COVID CT Tweet - MEAN',\n",
    "                                ('COVID-SPECIFIC CT Tweet (Dummy)', 'sum'):'COVID CT Tweet - COUNT',\n",
    "                                ('CT Tweet (Dummy)', 'mean'):'CT Tweet - MEAN',\n",
    "                                ('CT Tweet (Dummy)', 'sum'):'CT Tweet - COUNT',\n",
    "                                ('NON-COVID CT Tweet (Dummy)', 'mean'): 'NON-COVID CT Tweet - MEAN',\n",
    "                                ('NON-COVID CT Tweet (Dummy)', 'sum'):'NON-COVID CT Tweet - COUNT',\n",
    "                                ('retweet', 'mean'):'Retweets - MEAN',\n",
    "                                ('retweet', 'size'): 'Tweet Count',\n",
    "                                ('Non-CT Tweet', 'mean'):'Non-CT Tweet - MEAN',\n",
    "                                ('Non-CT Tweet', 'sum'):'Non-CT Tweet - COUNT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 35\n",
      "1 46\n",
      "2 89\n",
      "3 49\n",
      "4 7\n",
      "5 80\n",
      "6 17\n",
      "7 74\n",
      "8 93\n",
      "9 25\n",
      "10 5\n",
      "11 26\n",
      "12 36\n",
      "13 56\n",
      "14 44\n",
      "15 95\n",
      "16 71\n",
      "17 32\n",
      "18 69\n",
      "19 90\n",
      "20 43\n",
      "21 63\n",
      "22 67\n",
      "23 61\n",
      "24 82\n",
      "25 14\n",
      "26 83\n",
      "27 9\n",
      "28 77\n",
      "29 66\n",
      "30 92\n",
      "31 34\n",
      "32 53\n",
      "33 0\n",
      "34 21\n",
      "35 98\n",
      "36 68\n",
      "37 65\n",
      "38 19\n",
      "39 24\n",
      "40 3\n",
      "41 30\n",
      "42 59\n",
      "43 75\n",
      "44 64\n",
      "45 91\n",
      "46 10\n",
      "47 6\n",
      "48 28\n",
      "49 97\n",
      "50 81\n",
      "51 37\n",
      "52 42\n",
      "53 23\n",
      "54 39\n",
      "55 79\n",
      "56 47\n",
      "57 18\n",
      "58 16\n",
      "59 50\n",
      "60 87\n",
      "61 2\n",
      "62 20\n",
      "63 54\n",
      "64 78\n",
      "65 57\n",
      "66 48\n",
      "67 85\n",
      "68 86\n",
      "69 11\n",
      "70 99\n",
      "71 8\n",
      "72 1\n",
      "73 52\n",
      "74 55\n",
      "75 45\n",
      "76 29\n",
      "77 72\n",
      "78 70\n",
      "79 40\n",
      "80 60\n",
      "81 88\n",
      "82 13\n",
      "83 27\n",
      "84 12\n",
      "85 96\n",
      "86 62\n",
      "87 22\n",
      "88 73\n",
      "89 33\n",
      "90 41\n",
      "91 15\n",
      "92 38\n",
      "93 94\n",
      "94 31\n",
      "95 58\n",
      "96 51\n",
      "97 4\n",
      "98 84\n",
      "99 76\n"
     ]
    }
   ],
   "source": [
    "for i, chunk_path in enumerate(chunk_paths):\n",
    "    \n",
    "    chunk_num = chunk_path.split('_')[-1].split('.')[0]\n",
    "    print(i, chunk_num)\n",
    "    \n",
    "    for time_period in ('M', 'W'):\n",
    "\n",
    "        chunk = pd.read_csv(fr\"{MERGED_TWEET_CHUNK_READ_PATH}{chunk_path}\", usecols=cols_to_use, dtype=datatypes, parse_dates=['date'], date_parser=get_date)\n",
    "\n",
    "        chunk.rename(columns={'label':'COVID-SPECIFIC CT Tweet (Dummy)'}, inplace=True)\n",
    "        \n",
    "        # create \"Non-CT Tweet\" bool col\n",
    "        chunk['Non-CT Tweet'] = 1 - (chunk[['COVID-SPECIFIC CT Tweet (Dummy)', 'CT Tweet (Dummy)', 'NON-COVID CT Tweet (Dummy)']].sum(axis=1) > 0)\n",
    "\n",
    "        # MIGHT NEED 'user_id' TO BE AN INDEX TOO\n",
    "        collapsed_chunk = chunk.set_index('date').groupby([pd.Grouper(freq=f'1{time_period}'), 'user_id']).agg(agg_dict)\n",
    "        \n",
    "        collapsed_chunk.columns = collapsed_chunk.columns.to_flat_index()        \n",
    "        \n",
    "        collapsed_chunk.rename(columns=rename_dict, inplace=True)\n",
    "        collapsed_chunk.reset_index(inplace=True)\n",
    "        collapsed_chunk.set_index('user_id', inplace=True)\n",
    "        \n",
    "        all_dates = collapsed_chunk['date'].unique()\n",
    "        \n",
    "        collapsed_chunk = fill_missing_dates(collapsed_chunk)\n",
    "        # UNCOMMENT WHEN READY\n",
    "        collapsed_chunk.to_csv(fr\"{AGGREGATED_TWEET_CHUNK_SAVE_PATH}Chunk-{chunk_num}-AGG-BY-{time_period} - NO BERT.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERGE ALL COLLAPSED USERS' BEHAVIOUR CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_chunk_dfs = [pd.read_csv(fr\"{AGGREGATED_TWEET_CHUNK_SAVE_PATH}Chunk-{i}-AGG-BY-M - NO BERT.csv\") for i, chunk_path in enumerate(chunk_paths)]\n",
    "monthly_non_located_user_behaviour_df = pd.concat(month_chunk_dfs)\n",
    "\n",
    "week_chunk_dfs = [pd.read_csv(fr\"{AGGREGATED_TWEET_CHUNK_SAVE_PATH}Chunk-{i}-AGG-BY-W - NO BERT.csv\") for i, chunk_path in enumerate(chunk_paths)]\n",
    "weekly_non_located_user_behaviour_df = pd.concat(week_chunk_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82649"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(monthly_non_located_user_behaviour_df['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weekly_non_located_user_behaviour_df['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21707"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(month_chunk_dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83149"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(monthly_non_located_user_behaviour_df['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165298.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(monthly_non_located_user_behaviour_df) / 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGING USER BEHAVIOUR TO GEOLOCATED USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "located_users = pd.read_csv(r\"/arc/project/st-tlemieux-1/data/FINAL-CLEANED-GEOLOCATED-USERS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_final_CT_df = located_users.merge(monthly_non_located_user_behaviour_df,\n",
    "                   how='left',\n",
    "                   left_on='ID',\n",
    "                   right_on='user_id')\n",
    "\n",
    "weekly_final_CT_df = located_users.merge(weekly_non_located_user_behaviour_df,\n",
    "                   how='left',\n",
    "                   left_on='ID',\n",
    "                   right_on='user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW SAVE TO CSV AND WE'RE DONE HERE!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_BEHAVIOUR_SAVE_PATH_ROOT = \"/scratch/st-tlemieux-1/lfrymire/FINAL-CT-BEHAVIOUR-OUTPUT/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Usable FIPS</th>\n",
       "      <th>Usable STATE</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>COVID CT Tweet - MEAN</th>\n",
       "      <th>COVID CT Tweet - COUNT</th>\n",
       "      <th>CT Tweet - MEAN</th>\n",
       "      <th>CT Tweet - COUNT</th>\n",
       "      <th>NON-COVID CT Tweet - MEAN</th>\n",
       "      <th>NON-COVID CT Tweet - COUNT</th>\n",
       "      <th>Retweets - MEAN</th>\n",
       "      <th>Tweet Count</th>\n",
       "      <th>Non-CT Tweet - MEAN</th>\n",
       "      <th>Non-CT Tweet - COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120128474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>93.00</td>\n",
       "      <td>120128474.00</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>0.14</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>476.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>411.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120128474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>367.00</td>\n",
       "      <td>120128474.00</td>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>307.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>273.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120128474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>640.00</td>\n",
       "      <td>120128474.00</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>0.08</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>413.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>381.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120128474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>912.00</td>\n",
       "      <td>120128474.00</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>320.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>280.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120128474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>1185.00</td>\n",
       "      <td>120128474.00</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>0.07</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>439.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>407.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473210</th>\n",
       "      <td>170843799</td>\n",
       "      <td>20091.00</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>19780.00</td>\n",
       "      <td>170843799.00</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>43.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473211</th>\n",
       "      <td>170843799</td>\n",
       "      <td>20091.00</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>20549.00</td>\n",
       "      <td>170843799.00</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>47.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473212</th>\n",
       "      <td>170843799</td>\n",
       "      <td>20091.00</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>21311.00</td>\n",
       "      <td>170843799.00</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473213</th>\n",
       "      <td>170843799</td>\n",
       "      <td>20091.00</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>22060.00</td>\n",
       "      <td>170843799.00</td>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>48.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473214</th>\n",
       "      <td>170843799</td>\n",
       "      <td>20091.00</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>22804.00</td>\n",
       "      <td>170843799.00</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>35.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2473215 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  Usable FIPS Usable STATE  Unnamed: 0      user_id  \\\n",
       "0        120128474          NaN     COLORADO       93.00 120128474.00   \n",
       "1        120128474          NaN     COLORADO      367.00 120128474.00   \n",
       "2        120128474          NaN     COLORADO      640.00 120128474.00   \n",
       "3        120128474          NaN     COLORADO      912.00 120128474.00   \n",
       "4        120128474          NaN     COLORADO     1185.00 120128474.00   \n",
       "...            ...          ...          ...         ...          ...   \n",
       "2473210  170843799     20091.00       KANSAS    19780.00 170843799.00   \n",
       "2473211  170843799     20091.00       KANSAS    20549.00 170843799.00   \n",
       "2473212  170843799     20091.00       KANSAS    21311.00 170843799.00   \n",
       "2473213  170843799     20091.00       KANSAS    22060.00 170843799.00   \n",
       "2473214  170843799     20091.00       KANSAS    22804.00 170843799.00   \n",
       "\n",
       "               date  COVID CT Tweet - MEAN  COVID CT Tweet - COUNT  \\\n",
       "0        2019-01-31                   0.14                   65.00   \n",
       "1        2019-02-28                   0.11                   34.00   \n",
       "2        2019-03-31                   0.08                   32.00   \n",
       "3        2019-04-30                   0.12                   40.00   \n",
       "4        2019-05-31                   0.07                   32.00   \n",
       "...             ...                    ...                     ...   \n",
       "2473210  2021-02-28                   0.00                    0.00   \n",
       "2473211  2021-03-31                   0.00                    0.00   \n",
       "2473212  2021-04-30                   0.00                    0.00   \n",
       "2473213  2021-05-31                   0.00                    0.00   \n",
       "2473214  2021-06-30                   0.00                    0.00   \n",
       "\n",
       "         CT Tweet - MEAN  CT Tweet - COUNT  NON-COVID CT Tweet - MEAN  \\\n",
       "0                   0.14             65.00                       0.00   \n",
       "1                   0.11             34.00                       0.00   \n",
       "2                   0.08             32.00                       0.00   \n",
       "3                   0.12             40.00                       0.00   \n",
       "4                   0.07             32.00                       0.00   \n",
       "...                  ...               ...                        ...   \n",
       "2473210             0.00              0.00                       0.00   \n",
       "2473211             0.00              0.00                       0.00   \n",
       "2473212             0.00              0.00                       0.00   \n",
       "2473213             0.02              1.00                       0.02   \n",
       "2473214             0.00              0.00                       0.00   \n",
       "\n",
       "         NON-COVID CT Tweet - COUNT  Retweets - MEAN  Tweet Count  \\\n",
       "0                              0.00             0.00       476.00   \n",
       "1                              0.00             0.00       307.00   \n",
       "2                              0.00             0.00       413.00   \n",
       "3                              0.00             0.00       320.00   \n",
       "4                              0.00             0.00       439.00   \n",
       "...                             ...              ...          ...   \n",
       "2473210                        0.00             0.00        43.00   \n",
       "2473211                        0.00             0.00        47.00   \n",
       "2473212                        0.00             0.00        40.00   \n",
       "2473213                        1.00             0.00        49.00   \n",
       "2473214                        0.00             0.00        35.00   \n",
       "\n",
       "         Non-CT Tweet - MEAN  Non-CT Tweet - COUNT  \n",
       "0                       0.86                411.00  \n",
       "1                       0.89                273.00  \n",
       "2                       0.92                381.00  \n",
       "3                       0.88                280.00  \n",
       "4                       0.93                407.00  \n",
       "...                      ...                   ...  \n",
       "2473210                 1.00                 43.00  \n",
       "2473211                 1.00                 47.00  \n",
       "2473212                 1.00                 40.00  \n",
       "2473213                 0.98                 48.00  \n",
       "2473214                 1.00                 35.00  \n",
       "\n",
       "[2473215 rows x 16 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_final_CT_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1444070984"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_final_CT_df.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_final_CT_df.to_csv(f\"{FINAL_BEHAVIOUR_SAVE_PATH_ROOT}Monthly Behaviour - NO BERT.csv\")\n",
    "\n",
    "weekly_final_CT_df.to_csv(f\"{FINAL_BEHAVIOUR_SAVE_PATH_ROOT}Weekyl Behaviour - NO BERT.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
