{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN THIS AFTER CONCATENATING BERT OUTPUT TO CSV'S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_colwidth', 199)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGGREGATING USER BEHAVIOUR BY DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_TWEET_CHUNK_READ_PATH = r\"/scratch/st-tlemieux-1/lfrymire/BERT-input/FINAL-INPUTS/ALL-TWEETS/COV-CT-Tweets/\" #this should be a folder containing three folders - one for each type of CT tweet (make sure it ends in a slash)\n",
    "\n",
    "AGGREGATED_TWEET_CHUNK_SAVE_PATH = r\"/scratch/st-tlemieux-1/lfrymire/BERT-OUPUT/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_folder(folder):\n",
    "    \n",
    "    return [f for f in listdir(folder) if isfile(join(folder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_paths = get_files_in_folder(MERGED_TWEET_CHUNK_READ_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "cols_to_use = [BERT_CT_OUTPUT_COL, BERT_GEN_OUTPUT_COL, BERT_NON_CT_OUTPUT_COL, sentence1, 'user_id',\n",
    "               'CT Tweet (Dummy)','NON-COVID CT Tweet (Dummy)', 'date', 'retweet']\n",
    "\n",
    "bool_cols = [BERT_OUTPUT_COL_NAME, sentence1, 'CT Tweet (Dummy)','NON-COVID CT Tweet (Dummy)', 'retweet']\n",
    "int_cols = ['user_ID']\n",
    "# str_cols = ['Cleaned Tweet']\n",
    "\n",
    "# obj_cols = ['language']\n",
    "\n",
    "bool_cols_dict = {col:np.bool_ for col in bool_cols}\n",
    "int_cols_dict = {col:np.int0 for col in int_cols}\n",
    "# str_cols_dict = {col:str for col in str_cols}\n",
    "# obj_cols_dict = {col:str for col in obj_cols}\n",
    "\n",
    "# datatypes = {**bool_cols_dict, **str_cols_dict, **obj_cols_dict}\n",
    "# datatypes = {**bool_cols_dict, **obj_cols_dict}\n",
    "datatypes = {**bool_cols_dict, **int_cols_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(s):\n",
    "    return datetime.date(int(s[0:4]), int(s[5:7]), int(s[8:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {BERT_CT_OUTPUT_COL,:'mean',\n",
    "            BERT_GEN_OUTPUT_COL:'mean',\n",
    "            BERT_NON_CT_OUTPUT_COL:'mean',\n",
    "            'COVID-SPECIFIC CT Tweet (Dummy)':'mean',\n",
    "            'CT Tweet (Dummy)':'mean',\n",
    "            'NON-COVID CT Tweet (Dummy)':'mean',\n",
    "            'retweet':'mean'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk_path in enumerate(chunk_paths):\n",
    "    \n",
    "    for time_period in ('M', 'W'):\n",
    "\n",
    "        chunk = pd.read_csv(fr\"{MERGED_TWEET_CHUNK_READ_PATH}{chunk_path}\", usecols=cols_to_use, dtype=datatypes, parse_dates=['date'], date_parser=get_date)\n",
    "\n",
    "        chunk.rename(columns={'sentence1':'COVID-SPECIFIC CT Tweet (Dummy)'})\n",
    "\n",
    "        # MIGHT NEED 'user_id' TO BE AN INDEX TOO\n",
    "        collapsed_chunk = chunk.set_index('date').groupby([pd.Grouper(freq=f'1{time_period}'), 'user_id']).agg(agg_dict).droplevel('user_id').reset_index()\n",
    "\n",
    "        # UNCOMMENT WHEN READY\n",
    "#         collapsed_chunk.to_csv(fr\"{AGGREGATED_TWEET_CHUNK_SAVE_PATH}Chunk-{i}-AGG-BY-{time_period}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERGE ALL COLLAPSED USERS' BEHAVIOUR CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_chunk_dfs = [pd.read_csv(fr\"{AGGREGATED_TWEET_CHUNK_SAVE_PATH}Chunk-{i}-AGG-BY-M.csv\") for i, chunk_path in enumerate(chunk_paths)]\n",
    "monthly_non_located_user_behaviour_df = pd.concat(month_chunk_dfs)\n",
    "\n",
    "week_chunk_dfs = [pd.read_csv(fr\"{AGGREGATED_TWEET_CHUNK_SAVE_PATH}Chunk-{i}-AGG-BY-M.csv\") for i, chunk_path in enumerate(chunk_paths)]\n",
    "weekly_non_located_user_behaviour_df = pd.concat(week_chunk_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGING USER BEHAVIOUR TO GEOLOCATED USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "located_users = pd.read_csv(\"C:/Users/mikha/Dropbox/mikhael_misc/Projects/594/Twitter-Conspiracies/Geo Cross Referencing/FINAL-CLEANED-GEOLOCATED-USERS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_final_CT_df = located_users.merge(monthly_non_located_user_behaviour_df,\n",
    "                   how='left',\n",
    "                   left_on='ID',\n",
    "                   right_on='user_ID')\n",
    "\n",
    "weekly_final_CT_df = located_users.merge(weekly_non_located_user_behaviour_df,\n",
    "                   how='left',\n",
    "                   left_on='ID',\n",
    "                   right_on='user_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW SAVE TO CSV AND WE'RE DONE HERE!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
