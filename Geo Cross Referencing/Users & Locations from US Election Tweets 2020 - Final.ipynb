{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source:\n",
    "\n",
    "https://www.kaggle.com/manchunhui/us-election-2020-tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:97.5% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import reverse_geocoder\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import jellyfish\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:97.5% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikha\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (1,2,3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "biden_tweets = pd.read_csv(r\"C:/Users/mikha/OneDrive/Desktop/Dropbox/MIKHAEL NEW/mikhael school/Grad School/Master's/594/Data/US Election Tweets 2020/hashtag_joebiden.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "biden_tweets = biden_tweets[ biden_tweets['country']=='United States of America' ]\n",
    "\n",
    "biden_tweets = biden_tweets[['user_id', 'lat', 'long']]\n",
    "\n",
    "biden_tweets.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trump_tweets = pd.read_csv(r\"C:/Users/mikha/OneDrive/Desktop/Dropbox/MIKHAEL NEW/mikhael school/Grad School/Master's/594/Data/US Election Tweets 2020/hashtag_donaldtrump.csv\", lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trump_tweets = trump_tweets[ trump_tweets['country']=='United States of America' ]\n",
    "\n",
    "trump_tweets = trump_tweets[['user_id', 'lat', 'long']]\n",
    "\n",
    "trump_tweets.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_tweets_df = pd.concat([biden_tweets, trump_tweets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_tweets_df['lat'] = pd.to_numeric(all_tweets_df['lat'])\n",
    "all_tweets_df['long'] = pd.to_numeric(all_tweets_df['long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_tweets_df = all_tweets_df.groupby('user_id').agg(['unique'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# flatten column indices\n",
    "all_tweets_df.columns = all_tweets_df.columns.get_level_values(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up users with multiple locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tuple_is_close(tup, threshold):\n",
    "    '''\n",
    "    input = (x,y) = tuple of two elements\n",
    "    '''\n",
    "    if abs(tup[0] - tup[1]) < threshold:\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.3\n",
    "\n",
    "lat_good = []\n",
    "lon_good = []\n",
    "\n",
    "for i,row in all_tweets_df.iterrows():\n",
    "    \n",
    "    if len(row['lat']) > 1: # if multiple latitudes (and by extension multiple longitudes)\n",
    "        if all([tuple_is_close(x, THRESHOLD) for x in itertools.combinations(row['lat'], 2)]): #if all pairwise permutations of LATITUDES are within THRESHOLD degrees of eachother\n",
    "            lat_good.append(1)\n",
    "        else:\n",
    "            lat_good.append(0)\n",
    "\n",
    "        if all([tuple_is_close(x, THRESHOLD) for x in itertools.combinations(row['long'], 2)]): #if all pairwise permutations of LONGITUDES are within THRESHOLD degrees of eachother\n",
    "            lon_good.append(1)\n",
    "        else:\n",
    "            lon_good.append(0)\n",
    "    else: # if there's only one location for this user\n",
    "        lat_good.append(1)\n",
    "        lon_good.append(1)\n",
    "            \n",
    "                        \n",
    "\n",
    "all_tweets_df['Coordinates Dont Change'] = (np.array(lat_good)==1) & (np.array(lon_good)==1)\n",
    "\n",
    "all_tweets_df = all_tweets_df[ all_tweets_df['Coordinates Dont Change']==True ]\n",
    "\n",
    "del all_tweets_df['Coordinates Dont Change'], lat_good, lon_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_tweets_df.to_csv(r\"C:/Users/mikha/OneDrive/Desktop/Dropbox/MIKHAEL NEW/mikhael school/Grad School/Master's/594/Data/US Election Tweets 2020/US Election Geolocated Users.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse GeoCode from Coordinates to Counties/FIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Here we're just taking the first set of coordinates (even if there are multiple for a user).\n",
    "This shouldn't make a difference since we already filtered out all users with multiple coordinates that are far away from eachother.\n",
    "'''\n",
    "\n",
    "coords_list = []\n",
    "\n",
    "for i,row in all_tweets_df.iterrows():\n",
    "    coords_list.append((row['lat'][0], row['long'][0]))\n",
    "\n",
    "all_tweets_df['Coordinates'] = coords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del all_tweets_df['lat'], all_tweets_df['long'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter to Only Look Up CT Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_CT_users = pd.read_csv(r\"C:\\Users\\mikha\\Dropbox\\mikhael_misc\\Projects\\594\\Twitter-Conspiracies\\All CT Link and Hashtag Users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_tweets_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_tweets_df['user_id'] = pd.to_numeric(all_tweets_df['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocated_users = np.intersect1d(all_tweets_df['user_id'], all_CT_users['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df = all_tweets_df.set_index('user_id').loc[geolocated_users].reset_index().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_geo_lookup(coordinates):\n",
    "    location = reverse_geocoder.search(coordinates)[0]#['admin2']\n",
    "    return location['admin1'], location['admin2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Massachusetts', 'Worcester County')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_geo_lookup(all_tweets_df['Coordinates'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def reverse_geo_lookup(coordinates):\n",
    "#     try:\n",
    "#         return reverse_geocoder.search(coordinates)#[0]['admin2']\n",
    "#     except:\n",
    "#         return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 14874/14874 [7:23:52<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "all_tweets_df['Location'] = all_tweets_df['Coordinates'].progress_apply(reverse_geo_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_location = pd.DataFrame(all_tweets_df['Location'].tolist(), index=all_tweets_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df = all_tweets_df.merge(split_location, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df.rename(columns={0:'State', 1:'County'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_tweets_df['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df['State'] = all_tweets_df['State'].str.upper()\n",
    "all_tweets_df['County'] = all_tweets_df['County'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df.to_csv(r\"C:/Users/mikha/Dropbox/mikhael_misc/Projects/594/Twitter-Conspiracies/Geo Cross Referencing/Users Geolocated From US Election 2020.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT STEP:\n",
    "\n",
    "1. Convert County names to FIPS\n",
    "2. Merge with user master list (with suffix to indicate geodata source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIPS Import and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict_uppercase(d):\n",
    "    '''\n",
    "    input = dictionary\n",
    "    output = uppercase dictionary\n",
    "    '''\n",
    "    \n",
    "    return {key.upper(): value.upper() for key,value in d.items()}\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "\n",
    "def make_list_of_dicts_uppercase(list_of_dicts):\n",
    "    '''\n",
    "    input = list of dictionaries\n",
    "    output = uppercase list of dictionaries\n",
    "    '''\n",
    "    \n",
    "    return [make_dict_uppercase(d) for d in list_of_dicts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get (State & County) --> FIPS dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikha\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# import data from wikipedia\n",
    "fips = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_United_States_FIPS_codes_by_county\")[1]\n",
    "\n",
    "# remove all hyperlinks (these look like \"... County [h]\", etc.)\n",
    "fips['County or equivalent'] = fips['County or equivalent'].str.replace(r\"\\[.*\\]\",\"\")\n",
    "\n",
    "# convert to uppercase\n",
    "fips['County or equivalent'] = fips['County or equivalent'].apply(lambda x: x.upper())\n",
    "fips['State or equivalent'] = fips['State or equivalent'].apply(lambda x: x.upper())\n",
    "\n",
    "# replace \"St.\" with \"Saint\"\n",
    "fips['County or equivalent'] = [x.replace('ST.','SAINT') for x in fips['County or equivalent']]\n",
    "\n",
    "# remove everything after a comma in a county name (e.g. \"ANCHORAGE, MUNICIPALITY OF\")\n",
    "fips['County or equivalent'] = [x.split(',')[0] for x in fips['County or equivalent']]\n",
    "\n",
    "# replace DC info to correspond to GeoCov19 format\n",
    "dc_loc = fips[fips['County or equivalent']=='DISTRICT OF COLUMBIA'].index.tolist()[0]\n",
    "fips['State or equivalent'].loc[dc_loc] = 'WASHINGTON, D.C.'\n",
    "fips['County or equivalent'].loc[dc_loc] = 'WASHINGTON'\n",
    "\n",
    "########################################################################\n",
    "\n",
    "# create dictionary\n",
    "state_fips_dict = {k: f.groupby('County or equivalent')['FIPS'].apply(list).to_dict()\n",
    "     for k, f in fips.groupby('State or equivalent')}\n",
    "\n",
    "# clean dictionary\n",
    "for state in state_fips_dict:\n",
    "    for county in state_fips_dict[state]:\n",
    "        state_fips_dict[state][county] = state_fips_dict[state][county][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map county names to FIPS (using FIPS dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get FIPS from a single dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_match_counties(county, counties_dict):\n",
    "    '''\n",
    "    input = county we're searching for; dict of counties we're trying to match it to and their correspodning FIPS\n",
    "    output = name of the county that it's closest to\n",
    "    '''\n",
    "    # create list of jaro-winkler similarities between the misspelled county and all counties in the state\n",
    "    jaro_distances = np.array([jellyfish.jaro_winkler_similarity(county, county_from_list) for county_from_list in list(counties_dict.keys())])\n",
    "        \n",
    "    # return county with smallest jaro-winkler distance\n",
    "    return counties_dict[list(counties_dict.keys())[np.argmin(jaro_distances)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fips_from_loc(loc):\n",
    "    '''\n",
    "    input = tweet_location from US Election data: (STATE, COUNTY) tuple\n",
    "    output = FIPS code corresponding to county \n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        return state_fips_dict[ loc[0] ][ loc[1] ]\n",
    "    except:\n",
    "        try:\n",
    "            return fuzzy_match_counties(loc[1], state_fips_dict[loc[0]])\n",
    "        except Exception as e:\n",
    "            return np.nan\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df['State+County'] = list(zip(all_tweets_df['State'], all_tweets_df['County']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_tweets_df['FIPS'] = all_tweets_df['State+County'].apply(get_fips_from_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df = all_tweets_df[~all_tweets_df['FIPS'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_df.to_csv(r\"C:/Users/mikha/Dropbox/mikhael_misc/Projects/594/Twitter-Conspiracies/Geo Cross Referencing/Users Geolocated From US Election 2020.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with Master User List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_user_list_path = r\"C:/Users/mikha/Dropbox/mikhael_misc/Projects/594/Twitter-Conspiracies/All CT Link and Hashtag Users.csv\"\n",
    "\n",
    "MASTER_USER_LIST = pd.read_csv(master_user_list_path)\n",
    "\n",
    "del MASTER_USER_LIST['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_USER_LIST = MASTER_USER_LIST.merge(all_tweets_df, left_on='ID', right_on='user_id', how='left', suffixes=('', ' - ELECTION 2020'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Num CT Tweets - HT</th>\n",
       "      <th>Num CT Tweets - LINK</th>\n",
       "      <th>user_id</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>State+County</th>\n",
       "      <th>FIPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3632641633</td>\n",
       "      <td>310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.632642e+09</td>\n",
       "      <td>(40.0149856, -105.2705456)</td>\n",
       "      <td>COLORADO</td>\n",
       "      <td>BOULDER COUNTY</td>\n",
       "      <td>(COLORADO, BOULDER COUNTY)</td>\n",
       "      <td>8013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>94374562</td>\n",
       "      <td>306.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.437456e+07</td>\n",
       "      <td>(31.8160381, -99.5120986)</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>COLEMAN COUNTY</td>\n",
       "      <td>(TEXAS, COLEMAN COUNTY)</td>\n",
       "      <td>48083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>183301058</td>\n",
       "      <td>904.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1.833011e+08</td>\n",
       "      <td>(27.9477595, -82.458444)</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>HILLSBOROUGH COUNTY</td>\n",
       "      <td>(FLORIDA, HILLSBOROUGH COUNTY)</td>\n",
       "      <td>12057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1194604029365456896</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.194604e+18</td>\n",
       "      <td>(34.2331373, -102.4107493)</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>LAMB COUNTY</td>\n",
       "      <td>(TEXAS, LAMB COUNTY)</td>\n",
       "      <td>48279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>14709515</td>\n",
       "      <td>297.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.470952e+07</td>\n",
       "      <td>(33.687438799999995, -80.4363743)</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>SUMTER COUNTY</td>\n",
       "      <td>(SOUTH CAROLINA, SUMTER COUNTY)</td>\n",
       "      <td>45085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027927</th>\n",
       "      <td>179236473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.792365e+08</td>\n",
       "      <td>(27.7567667, -81.4639835)</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>POLK COUNTY</td>\n",
       "      <td>(FLORIDA, POLK COUNTY)</td>\n",
       "      <td>12105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028396</th>\n",
       "      <td>1270528891774525440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.270529e+18</td>\n",
       "      <td>(42.2681569, -83.7312291)</td>\n",
       "      <td>MICHIGAN</td>\n",
       "      <td>WASHTENAW COUNTY</td>\n",
       "      <td>(MICHIGAN, WASHTENAW COUNTY)</td>\n",
       "      <td>26161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028662</th>\n",
       "      <td>56342154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.634215e+07</td>\n",
       "      <td>(29.4246002, -98.4951405)</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>BEXAR COUNTY</td>\n",
       "      <td>(TEXAS, BEXAR COUNTY)</td>\n",
       "      <td>48029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028745</th>\n",
       "      <td>1213901815827165184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.213902e+18</td>\n",
       "      <td>(40.8517224, -73.0992188)</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>SUFFOLK COUNTY</td>\n",
       "      <td>(NEW YORK, SUFFOLK COUNTY)</td>\n",
       "      <td>36103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028783</th>\n",
       "      <td>837976136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.379761e+08</td>\n",
       "      <td>(35.48463579999999, -97.3940479)</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>OKLAHOMA COUNTY</td>\n",
       "      <td>(OKLAHOMA, OKLAHOMA COUNTY)</td>\n",
       "      <td>40109.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13128 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ID  Num CT Tweets - HT  Num CT Tweets - LINK       user_id                        Coordinates           State               County                     State+County     FIPS\n",
       "39                3632641633               310.0                   NaN  3.632642e+09         (40.0149856, -105.2705456)        COLORADO       BOULDER COUNTY       (COLORADO, BOULDER COUNTY)   8013.0\n",
       "49                  94374562               306.0                   NaN  9.437456e+07          (31.8160381, -99.5120986)           TEXAS       COLEMAN COUNTY          (TEXAS, COLEMAN COUNTY)  48083.0\n",
       "96                 183301058               904.0                 215.0  1.833011e+08           (27.9477595, -82.458444)         FLORIDA  HILLSBOROUGH COUNTY   (FLORIDA, HILLSBOROUGH COUNTY)  12057.0\n",
       "130      1194604029365456896                90.0                   NaN  1.194604e+18         (34.2331373, -102.4107493)           TEXAS          LAMB COUNTY             (TEXAS, LAMB COUNTY)  48279.0\n",
       "147                 14709515               297.0                   NaN  1.470952e+07  (33.687438799999995, -80.4363743)  SOUTH CAROLINA        SUMTER COUNTY  (SOUTH CAROLINA, SUMTER COUNTY)  45085.0\n",
       "...                      ...                 ...                   ...           ...                                ...             ...                  ...                              ...      ...\n",
       "1027927            179236473                 NaN                   1.0  1.792365e+08          (27.7567667, -81.4639835)         FLORIDA          POLK COUNTY           (FLORIDA, POLK COUNTY)  12105.0\n",
       "1028396  1270528891774525440                 NaN                   1.0  1.270529e+18          (42.2681569, -83.7312291)        MICHIGAN     WASHTENAW COUNTY     (MICHIGAN, WASHTENAW COUNTY)  26161.0\n",
       "1028662             56342154                 NaN                   1.0  5.634215e+07          (29.4246002, -98.4951405)           TEXAS         BEXAR COUNTY            (TEXAS, BEXAR COUNTY)  48029.0\n",
       "1028745  1213901815827165184                 NaN                   1.0  1.213902e+18          (40.8517224, -73.0992188)        NEW YORK       SUFFOLK COUNTY       (NEW YORK, SUFFOLK COUNTY)  36103.0\n",
       "1028783            837976136                 NaN                   1.0  8.379761e+08   (35.48463579999999, -97.3940479)        OKLAHOMA      OKLAHOMA COUNTY      (OKLAHOMA, OKLAHOMA COUNTY)  40109.0\n",
       "\n",
       "[13128 rows x 9 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MASTER_USER_LIST[~MASTER_USER_LIST['FIPS'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_USER_LIST.rename(columns={'Coordinates':'Coordinates - ELECTION 2020', 'State+County':'State+County - ELECTION 2020', 'FIPS': 'FIPS - ELECTION 2020'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_USER_LIST.drop(['user_id','State','County'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_USER_LIST.to_csv(r'C:/Users/mikha/Dropbox/mikhael_misc/Projects/594/Twitter-Conspiracies/Geo Cross Referencing/Master User List - GEOLOCATED.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Num CT Tweets - HT</th>\n",
       "      <th>Num CT Tweets - LINK</th>\n",
       "      <th>Coordinates - ELECTION 2020</th>\n",
       "      <th>State+County - ELECTION 2020</th>\n",
       "      <th>FIPS - ELECTION 2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>948955244</td>\n",
       "      <td>9162.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1041624996265701378</td>\n",
       "      <td>2095.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25420415</td>\n",
       "      <td>4030.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71777998</td>\n",
       "      <td>4684.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1721052956</td>\n",
       "      <td>6051.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028956</th>\n",
       "      <td>1304140679573106689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028957</th>\n",
       "      <td>78607938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028958</th>\n",
       "      <td>345261628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028959</th>\n",
       "      <td>1298989066076057600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028960</th>\n",
       "      <td>1083375427517845504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1028961 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ID  Num CT Tweets - HT  Num CT Tweets - LINK Coordinates - ELECTION 2020 State+County - ELECTION 2020  FIPS - ELECTION 2020\n",
       "0                  948955244              9162.0                   NaN                         NaN                          NaN                   NaN\n",
       "1        1041624996265701378              2095.0                   2.0                         NaN                          NaN                   NaN\n",
       "2                   25420415              4030.0                   NaN                         NaN                          NaN                   NaN\n",
       "3                   71777998              4684.0                   NaN                         NaN                          NaN                   NaN\n",
       "4                 1721052956              6051.0                   NaN                         NaN                          NaN                   NaN\n",
       "...                      ...                 ...                   ...                         ...                          ...                   ...\n",
       "1028956  1304140679573106689                 NaN                   1.0                         NaN                          NaN                   NaN\n",
       "1028957             78607938                 NaN                   1.0                         NaN                          NaN                   NaN\n",
       "1028958            345261628                 NaN                   1.0                         NaN                          NaN                   NaN\n",
       "1028959  1298989066076057600                 NaN                   1.0                         NaN                          NaN                   NaN\n",
       "1028960  1083375427517845504                 NaN                   1.0                         NaN                          NaN                   NaN\n",
       "\n",
       "[1028961 rows x 6 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MASTER_USER_LIST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
