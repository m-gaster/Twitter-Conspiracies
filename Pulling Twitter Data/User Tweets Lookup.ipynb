{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import twint\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta, date\n",
    "import json\n",
    "from collections import Counter\n",
    "from ast import literal_eval\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_colwidth', 199)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_USER_IDS_PATH = WHERE YOU STORE THE FILE WITH ALL CONSPIRACY USER IDS\n",
    "\n",
    "\n",
    "#DELETE THIS:\n",
    "ALL_USER_IDS_PATH = r\"C:/Users/crackcocaine69xxx/Python Stuff/594/Twint/Getting Conspiracy Hashtag Users/All User IDs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_IDs = pd.read_csv(fr\"{ALL_USER_IDS_PATH}\")\n",
    "\n",
    "all_user_IDs = all_user_IDs.set_index('ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean tweets function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reply_to(obs):\n",
    "    \n",
    "    if len(obs) != 0:\n",
    "\n",
    "        return [int(x['id']) for x in (obs)]\n",
    "            \n",
    "    \n",
    "# vec_clean_reply_to = np.vectorize(clean_reply_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_replacement_dict = {'en': 1, 'und':0}\n",
    "\n",
    "def replace_0_or_1(x):\n",
    "    if x not in (0,1):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def clean_language(series):\n",
    "    local_series = series.map(language_replacement_dict)\n",
    "    \n",
    "    return [replace_0_or_1(x) for x in local_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(df):\n",
    "    local_df = df\n",
    "    \n",
    "    \n",
    "    # drop redundant cols\n",
    "    local_df.drop(['created_at', 'timezone', 'cashtags', 'user_id_str', 'photos', 'video', 'thumbnail', 'translate', 'trans_src', 'trans_dest', 'name', 'search', 'day', 'hour', 'link', 'quote_url'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # convert date to datetime\n",
    "    local_df['date'] = pd.to_datetime(local_df['date'])\n",
    "    \n",
    "    \n",
    "    # clean \"reply_to\" field\n",
    "    local_df['reply_to'] = [clean_reply_to(x) for x in local_df['reply_to']]\n",
    "    \n",
    "    \n",
    "    # clean \"language field\"\n",
    "    local_df['language'] = clean_language(local_df['language'])\n",
    "    \n",
    "    \n",
    "    return local_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH_ROOT = FOLDER WHERE YOU WANT TO SAVE TWEETS\n",
    "\n",
    "#DELETE THIS:\n",
    "#PATH_ROOT = \"C:/Users/crackcocaine69xxx/Python Stuff/594/Twint/Looking Up All Conspiracy Hashtag User Tweets/All Conspiracy Tweeters' Tweets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_user(ID):\n",
    "    '''\n",
    "    ID = str(twitter user_i ID)\n",
    "    '''\n",
    "    c = twint.Config()\n",
    "        \n",
    "    c.User_id = ID\n",
    "        \n",
    "    c.Hide_output = True    \n",
    "    \n",
    "    # find shadow-banned accounts too - this apparently slows things down considerably\n",
    "    c.Profile_full = True    \n",
    "    \n",
    "    c.Since = '2019-01-01'\n",
    "\n",
    "    c.Pandas = True\n",
    "\n",
    "    twint.run.Search(c)\n",
    "    \n",
    "    clean_tweets(twint.storage.panda.Tweets_df).to_csv(fr\"{PATH_ROOT}{ID}_TWEETS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noData'globalObjects'\n",
      "sleeping for 1.0 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "for i, row in all_user_IDs.iterrows():\n",
    "    \n",
    "    if row['Searched'] != 1:\n",
    "    \n",
    "        search_for_user( str(row.name) )\n",
    "\n",
    "        all_user_IDs['Searched'].loc[row.name] = 1\n",
    "\n",
    "        if i % 100:    #save .csv every 100 users (essentially update progress)\n",
    "\n",
    "            all_user_IDs.to_csv(ALL_USER_IDS_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split All User IDs for Concurrent Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod_10 in list(range(0,10)): #every 10 observations\n",
    "    \n",
    "    all_user_IDs.iloc[mod_10::10].to_csv(fr\"C:/Users/crackcocaine69xxx/Python Stuff/594/Twint/Getting Conspiracy Hashtag Users/All User IDs - Split {mod_10}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
