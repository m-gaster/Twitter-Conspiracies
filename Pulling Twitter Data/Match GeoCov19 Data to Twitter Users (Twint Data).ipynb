{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable codefolding/main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_colwidth', 199)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "1. Identify US users \n",
    "2. Identify US Tweets \n",
    "3. Delete all obs. without US User or Tweet \n",
    "4. Match to list of users we collected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import GeoCov19 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(r\"C:/Users/crackcocaine69xxx/Python Stuff/594/GeoCoV19 Data/geo_feb_01_10/geo_2020-02-01/geo_2020-02-01.json\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELETE THIS LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict_uppercase(d):\n",
    "    '''\n",
    "    input = dictionary\n",
    "    output = uppercase dictionary\n",
    "    '''\n",
    "    \n",
    "    return {key.upper(): value.upper() for key,value in d.items()}\n",
    "\n",
    "df['user_location'] = df['user_location'].apply(make_dict_uppercase)\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "\n",
    "def make_list_of_dicts_uppercase(list_of_dicts):\n",
    "    '''\n",
    "    input = list of dictionaries\n",
    "    output = uppercase list of dictionaries\n",
    "    '''\n",
    "    \n",
    "    return [make_dict_uppercase(d) for d in list_of_dicts]\n",
    "\n",
    "\n",
    "df['tweet_locations'] = df['tweet_locations'].apply(make_list_of_dicts_uppercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get (State & County) --> FIPS dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from wikipedia\n",
    "fips = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_United_States_FIPS_codes_by_county\")[1]\n",
    "\n",
    "# remove all hyperlinks (these look like \"... County [h]\", etc.)\n",
    "fips['County or equivalent'] = fips['County or equivalent'].str.replace(r\"\\[.*\\]\",\"\")\n",
    "\n",
    "# convert to uppercase\n",
    "fips['County or equivalent'] = fips['County or equivalent'].apply(lambda x: x.upper())\n",
    "fips['State or equivalent'] = fips['State or equivalent'].apply(lambda x: x.upper())\n",
    "\n",
    "# replace \"St.\" with \"Saint\"\n",
    "fips['County or equivalent'] = [x.replace('ST.','SAINT') for x in fips['County or equivalent']]\n",
    "\n",
    "# remove everything after a comma in a county name (e.g. \"ANCHORAGE, MUNICIPALITY OF\")\n",
    "fips['County or equivalent'] = [x.split(',')[0] for x in fips['County or equivalent']]\n",
    "\n",
    "# replace DC info to correspond to GeoCov19 format\n",
    "dc_loc = fips[fips['County or equivalent']=='DISTRICT OF COLUMBIA'].index.tolist()[0]\n",
    "fips['State or equivalent'].loc[dc_loc] = 'WASHINGTON, D.C.'\n",
    "fips['County or equivalent'].loc[dc_loc] = 'WASHINGTON'\n",
    "\n",
    "########################################################################\n",
    "\n",
    "# create dictionary\n",
    "state_fips_dict = {k: f.groupby('County or equivalent')['FIPS'].apply(list).to_dict()\n",
    "     for k, f in fips.groupby('State or equivalent')}\n",
    "\n",
    "# clean dictionary\n",
    "for state in state_fips_dict:\n",
    "    for county in state_fips_dict[state]:\n",
    "        state_fips_dict[state][county] = state_fips_dict[state][county][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map county names to FIPS (using FIPS dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fips_from_loc(loc):\n",
    "    '''\n",
    "    input = tweet_location from GeoCov19 data (single dictionary)\n",
    "    output = FIPS code corresponding to counties mentioned\n",
    "    '''\n",
    "\n",
    "    if loc['COUNTRY_CODE']=='US':\n",
    "\n",
    "        try:\n",
    "\n",
    "            if loc['COUNTY'].split(\" \")[-1] in ('COUNTY', 'PARISH'):\n",
    "\n",
    "                return state_fips_dict[ loc['STATE'] ] [loc['COUNTY'] ]\n",
    "\n",
    "            elif 'COUNTY' in loc:\n",
    "\n",
    "                try:\n",
    "\n",
    "                    return state_fips_dict[ loc['STATE'] ] [loc['COUNTY'] + \" \" + \"COUNTY\"]\n",
    "\n",
    "                except Exception as e:\n",
    "\n",
    "                    pass\n",
    "        \n",
    "        except Exception as e:\n",
    "\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fips_from_list_of_locs(tweet_locs):\n",
    "    '''\n",
    "    input = tweet_locations from GeoCov19 data (list of dicts)\n",
    "    output = list of FIPS codes corresponding to counties mentioned\n",
    "    '''\n",
    "\n",
    "    temp_list = [get_fips_from_loc(loc, tweet_locs) for loc in tweet_locs]\n",
    "    \n",
    "    return [x for x in temp_list if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def OG_get_fips_from_list_of_locs(tweet_locs):\n",
    "#     '''\n",
    "#     input = tweet_locations from GeoCov19 data (list of dicts)\n",
    "#     output = list of FIPS codes corresponding to counties mentioned\n",
    "#     '''\n",
    "#     tweet_FIPS = []\n",
    "    \n",
    "#     for loc in tweet_locs: #there are no longer any empty locs so we don't have an if-else for them\n",
    "        \n",
    "#         if loc['COUNTRY_CODE']=='US':\n",
    "\n",
    "#             try:\n",
    "                \n",
    "#                 if loc['COUNTY'].split(\" \")[-1] in ('COUNTY', 'PARISH'):\n",
    "                    \n",
    "#                     tweet_FIPS.append(state_fips_dict[ loc['STATE'] ] [loc['COUNTY'] ])\n",
    "                                \n",
    "#                 elif 'COUNTY' in loc:\n",
    "                    \n",
    "#                     try:\n",
    "                        \n",
    "#                         tweet_FIPS.append(state_fips_dict[ loc['STATE'] ] [loc['COUNTY'] + \" \" + \"COUNTY\"])\n",
    "                        \n",
    "#                     except Exception as e:\n",
    "                        \n",
    "#                         print('0 ', e, '\\n')\n",
    "#                         print(loc, '\\n')\n",
    "#                         print(tweet_locs, '\\n \\n')\n",
    "                    \n",
    "#             except Exception as e:\n",
    "                \n",
    "#                 try:\n",
    "                    \n",
    "#                     print((loc['STATE'], loc['COUNTY']),',', '\\n')\n",
    "#                     print('1 ', e, '\\n')\n",
    "#                     print(loc, '\\n')\n",
    "#                     print(tweet_locs, '\\n')\n",
    "#                     print(state_fips_dict[loc['STATE']], '\\n')\n",
    "#                     print(state_fips_dict[loc['STATE']][loc['COUNTY']], '\\n')\n",
    "#                     print('\\n \\n')\n",
    "                    \n",
    "#                 except:\n",
    "                    \n",
    "#                     pass\n",
    "#                     print('2 ', e, '\\n')\n",
    "#                     print(loc, '\\n')\n",
    "#                     print(tweet_locs, '\\n \\n')\n",
    "\n",
    "#     return tweet_FIPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEED TO INSPECT COUNTY MAPPINGS TO ENSURE THAT IT PICKS UP ON STRINGS WELL\n",
    "\n",
    "\n",
    "# ALL REPLACEMENTS MUST BE DONE IN \"fips\"\n",
    "* ~\"Pointe Coupee Parish County\" should be \"Pointe Coupee Parish\"~\n",
    "* ~Need to replace \"St.\" with \"Saint\" in \"fips\"~\n",
    "* Fix counties that aren't cross-referenced correctly:\n",
    "    * \"D.C.\"\n",
    "    * \"SAN FRANCISCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Tweet FIPS'] = df['tweet_locations'].apply(get_fips_from_list_of_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['User FIPS'] = df['user_location'].apply(get_fips_from_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
